{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics as stat\n",
    "import math\n",
    "import pickle\n",
    "import gzip\n",
    "import sklearn\n",
    "import graphviz\n",
    "from graphviz import Source\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17290 entries, 0 to 17289\n",
      "Data columns (total 20 columns):\n",
      "date             17290 non-null int32\n",
      "bedrooms         17290 non-null int64\n",
      "bathrooms        17290 non-null float64\n",
      "sqft_living      17290 non-null int64\n",
      "sqft_lot         17290 non-null int64\n",
      "floors           17290 non-null float64\n",
      "waterfront       17290 non-null int64\n",
      "view             17290 non-null int64\n",
      "condition        17290 non-null int64\n",
      "grade            17290 non-null int64\n",
      "sqft_above       17290 non-null int64\n",
      "sqft_basement    17290 non-null int64\n",
      "yr_built         17290 non-null int64\n",
      "yr_renovated     17290 non-null int64\n",
      "zipcode          17290 non-null int64\n",
      "lat              17290 non-null float64\n",
      "long             17290 non-null float64\n",
      "sqft_living15    17290 non-null int64\n",
      "sqft_lot15       17290 non-null int64\n",
      "price            17290 non-null int64\n",
      "dtypes: float64(4), int32(1), int64(15)\n",
      "memory usage: 2.6 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4323 entries, 0 to 4322\n",
      "Data columns (total 19 columns):\n",
      "0     4323 non-null int32\n",
      "1     4323 non-null int64\n",
      "2     4323 non-null float64\n",
      "3     4323 non-null int64\n",
      "4     4323 non-null int64\n",
      "5     4323 non-null float64\n",
      "6     4323 non-null int64\n",
      "7     4323 non-null int64\n",
      "8     4323 non-null int64\n",
      "9     4323 non-null int64\n",
      "10    4323 non-null int64\n",
      "11    4323 non-null int64\n",
      "12    4323 non-null int64\n",
      "13    4323 non-null int64\n",
      "14    4323 non-null int64\n",
      "15    4323 non-null float64\n",
      "16    4323 non-null float64\n",
      "17    4323 non-null int64\n",
      "18    4323 non-null int64\n",
      "dtypes: float64(4), int32(1), int64(14)\n",
      "memory usage: 624.9 KB\n"
     ]
    }
   ],
   "source": [
    "#read in csv files. drop unknown column\n",
    "traindf = pd.read_csv('train_data.csv', engine='python')\n",
    "traindf.drop(traindf.columns[traindf.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
    "testdf = pd.read_csv('val_data.csv', engine='python')\n",
    "testdf.drop(testdf.columns[testdf.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
    "\n",
    "#drop the id information becuse it does not matter\n",
    "traindf.drop(traindf.columns[traindf.columns.str.contains('id',case = False)],axis = 1, inplace = True)\n",
    "testdf.drop(testdf.columns[testdf.columns.str.contains('id',case = False)],axis = 1, inplace = True)\n",
    "\n",
    "#clean the date information\n",
    "traindf['date'] = traindf['date'].str.replace(\"(T).*\",\"\").astype(int)\n",
    "testdf['date'] = testdf['date'].str.replace(\"(T).*\",\"\").astype(int)\n",
    "\n",
    "traindf.info()\n",
    "traindf.head()\n",
    "\n",
    "\n",
    "#Creates a copy of the training df so we can arrange our data and correctly format it\n",
    "traindfy = traindf.copy()\n",
    "traindfX = traindf.copy()\n",
    "testX = testdf.copy()\n",
    "\n",
    "\n",
    "#creates y and X df\n",
    "y = traindfy\n",
    "X = traindfX\n",
    "\n",
    "#Shows us our data for X\n",
    "X.drop(['price'], axis=1, inplace=True)\n",
    "traindfX.columns = range(traindfX.shape[1])\n",
    "testX.columns = range(testX.shape[1])\n",
    "X.head(10), traindf.head()\n",
    "testX.head()\n",
    "testX.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    353000\n",
       "1    300523\n",
       "2    435000\n",
       "3    800000\n",
       "4    417500\n",
       "Name: price, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shows us our data for y \n",
    "y = traindfy['price']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data (necessary for other classifiers)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12967, 19)\n",
      "(4323, 19)\n",
      "(12967,)\n",
      "(4323,)\n"
     ]
    }
   ],
   "source": [
    "#checking for correct array sizes\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinReg Score:  0.7112455445564347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adam Salyers\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:434: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#actual linear regression\n",
    "Lregression = LinearRegression().fit(X.values, y)\n",
    "print(\"LinReg Score: \",Lregression.score(X, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.01410090e+07 4.00000000e+00 2.75000000e+00 ... 2.90000000e+03\n",
      "  6.75200000e+03 6.31093508e+05]\n",
      " [2.01504010e+07 3.00000000e+00 2.25000000e+00 ... 1.62000000e+03\n",
      "  7.42900000e+03 4.96144286e+05]\n",
      " [2.01408190e+07 2.00000000e+00 1.50000000e+00 ... 3.86000000e+03\n",
      "  1.51081000e+05 6.99677002e+05]\n",
      " ...\n",
      " [2.01409080e+07 3.00000000e+00 1.50000000e+00 ... 1.84000000e+03\n",
      "  9.30500000e+03 3.50416123e+05]\n",
      " [2.01406100e+07 5.00000000e+00 3.25000000e+00 ... 3.55000000e+03\n",
      "  1.39170000e+04 1.37951369e+06]\n",
      " [2.01410170e+07 3.00000000e+00 1.75000000e+00 ... 1.82000000e+03\n",
      "  1.81510000e+04 3.58512595e+05]]\n",
      "0.7099535313823915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adam Salyers\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:434: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n",
      "C:\\Users\\Adam Salyers\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:434: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nThe score of accuracy averages at about 0.704 which is lower than when we dont\\nuse cross validation. When I increasee the fold size the accuracy goes down. \\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "#Predict using cross validation with 10 folds\n",
    "predictions = Lregression.predict(testX)\n",
    "\n",
    "#Print the predictions\n",
    "print(predictions)\n",
    "\n",
    "#Print mean score fo the cross validation \n",
    "scores = cross_val_score(Lregression, X, y, cv=2)\n",
    "print(np.mean(scores))\n",
    "\n",
    "'''\n",
    "The score of accuracy averages at about 0.704 which is lower than when we dont\n",
    "use cross validation. When I increasee the fold size the accuracy goes down. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Log Regress don't run it takes too long\n",
    "#Logreg = LogisticRegression(solver='liblinear', random_state=0).fit(X, y)\n",
    "#print(\"LogReg Score: \",Logreg.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#***dont run takes foreer will look at it later*** \n",
    "#clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "#clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree seen below is extremely hard to grade since we are looking at the individual house prices.\n",
    "\n",
    "The Gini score given is always going to be really high, becuase in all liklihood there is only one house per price.\n",
    "\n",
    "So instead we need to split the price into ranges, or bins, and then re-enter the correct ranges for the prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision tree classifier\n",
    "#Dectree = DecisionTreeClassifier(max_depth = 5).fit(X,y)\n",
    "#Source(export_graphviz(Dectree, out_file = None, feature_names = list(X.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the range of the price values\n",
    "#Pricemin = y_train.min()\n",
    "#Pricemax = y_train.max()\n",
    "\n",
    "#print(\"Min is: \", Pricemin, \"Max is: \", Pricemax)\n",
    "\n",
    "#Creating our range\n",
    "#Priceranges = np.linspace(Pricemin,Pricemax,15)\n",
    "\n",
    "#Range_y = y_train.copy()\n",
    "#Range_y = np.array(Range_y.values)\n",
    "\n",
    "#for i in range(len(Range_y)):\n",
    "    #for j in range(len(Priceranges)):\n",
    "        #if Range_y[i] <= Priceranges[j+1]: \n",
    "            #Range_y[i] = str(Priceranges[j])+\"-\"+str(Priceranges[j+1])\n",
    "            #break\n",
    "            \n",
    "\n",
    "#print(Range_y)\n",
    "\n",
    "#Now that we have our dataset lets create a new tree and compare!\n",
    "#Dectree = DecisionTreeClassifier(max_depth = 10).fit(X,Range_y)\n",
    "#Source(export_graphviz(Dectree, out_file = None, feature_names = list(X.columns)))\n",
    "\n",
    "#Much Better Right!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM classifier\n",
    "SVMreg = svm.SVC(kernel='rbf').fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = SVMreg.predict(X_test)\n",
    "print(predict)\n",
    "#print(mean_squared_error(y_test.values,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0  1     2     3      4    5  6  7  8   9    10   11    12  13  \\\n",
      "0      20141002  3  1.75  2190   7021  1.0  0  2  4   7  1390  800  1953   0   \n",
      "1      20150105  3  2.50  2370   6840  2.0  0  0  3   9  2370    0  1987   0   \n",
      "2      20140617  2  1.00  1230   3800  1.0  0  0  3   7  1230    0  1928   0   \n",
      "3      20141124  4  2.25  2510   9963  1.0  0  0  4   9  2200  310  1967   0   \n",
      "4      20140818  3  1.00  1160   7491  1.0  0  0  4   6  1160    0  1917   0   \n",
      "...         ... ..   ...   ...    ...  ... .. .. ..  ..   ...  ...   ...  ..   \n",
      "17285  20140804  3  2.50  1920   3867  2.0  0  0  3   8  1920    0  2005   0   \n",
      "17286  20150128  4  4.50  3420   7440  3.0  0  0  3   9  3420    0  2014   0   \n",
      "17287  20150401  3  1.75  1970  54450  1.0  0  0  3   8  1570  400  1980   0   \n",
      "17288  20140805  3  2.25  1980   8775  1.0  0  0  3   7  1290  690  1959   0   \n",
      "17289  20140610  5  4.00  3760  28040  2.0  0  0  3  10  3760    0  1983   0   \n",
      "\n",
      "          14       15       16    17     18  \n",
      "0      98178  47.5033 -122.232  2180   7155  \n",
      "1      98119  47.6503 -122.366  1590   4400  \n",
      "2      98115  47.6797 -122.292  1610   3800  \n",
      "3      98005  47.5973 -122.177  3110   9963  \n",
      "4      98177  47.7024 -122.359  1800   2267  \n",
      "...      ...      ...      ...   ...    ...  \n",
      "17285  98029  47.5538 -121.994  2190   3841  \n",
      "17286  98103  47.6875 -122.330  1360   5580  \n",
      "17287  98075  47.5936 -122.012  2460  36677  \n",
      "17288  98177  47.7753 -122.359  1550   9240  \n",
      "17289  98033  47.6489 -122.183  3430  35096  \n",
      "\n",
      "[17290 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
